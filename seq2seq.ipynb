{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sutd](sutd.png)\n",
    "## <center>50.040 Natural Language Processing, Summer 2020<center>\n",
    "<center>**Homework 4**\n",
    "\n",
    "<center>**Due 31 July 2020, 5pm** <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your student ID and name**\n",
    "\n",
    "ID:\n",
    "\n",
    "Name:\n",
    "\n",
    "Students whom you have discussed with (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "from collections import namedtuple\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Neural Machine Translation [25 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_TOKEN = '</s>'\n",
    "START_TOKEN = '<s>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, sent_pairs, src_word2idx, tgt_word2idx, tokenizer, max_len):\n",
    "        self.pairs = sent_pairs\n",
    "        self.src_w2i = src_word2idx\n",
    "        self.tgt_w2i = tgt_word2idx\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = []\n",
    "        tgt_ids = []\n",
    "        src = self.pairs[idx].src\n",
    "        tgt = self.pairs[idx].tgt\n",
    "        \n",
    "        src_words = self.tokenizer(src)\n",
    "        tgt_words = self.tokenizer(tgt)\n",
    "        for i in src_words:\n",
    "            try:\n",
    "                idx = self.src_w2i[i]\n",
    "            except KeyError:\n",
    "                idx = self.src_w2i[UNK_TOKEN]\n",
    "            src_ids.append(idx)\n",
    "        for j in tgt_words:\n",
    "            try:\n",
    "                idx = self.tgt_w2i[j]\n",
    "            except KeyError:\n",
    "                idx = self.tgt_w2i[UNK_TOKEN]\n",
    "            tgt_ids.append(idx)\n",
    "        \n",
    "        src_length = len(src_ids)\n",
    "        tgt_length = len(tgt_ids)\n",
    "        if src_length < self.max_len:\n",
    "            src_ids = src_ids + [self.src_w2i[STOP_TOKEN]] + [self.src_w2i[PAD_TOKEN]] * (self.max_len - src_length - 1)\n",
    "            assert len(src_ids) == self.max_len\n",
    "            src_length += 1\n",
    "        else:\n",
    "            src_ids = src_ids[:self.max_len-1] + [self.src_w2i[STOP_TOKEN]]\n",
    "            src_length = self.max_len\n",
    "            \n",
    "        if tgt_length < self.max_len-1:\n",
    "            tgt_ids = [self.tgt_w2i[START_TOKEN]] + tgt_ids + [self.tgt_w2i[STOP_TOKEN]] +\\\n",
    "            [self.tgt_w2i[PAD_TOKEN]] * (self.max_len - tgt_length - 2)\n",
    "            assert len(tgt_ids) == self.max_len\n",
    "            tgt_length += 2\n",
    "        else:\n",
    "            tgt_ids = [self.tgt_w2i[START_TOKEN]] + tgt_ids[:self.max_len-2] + [self.tgt_w2i[STOP_TOKEN]]\n",
    "            tgt_length = self.max_len\n",
    "            \n",
    "        src_mask = np.zeros(self.max_len)\n",
    "        tgt_mask = np.zeros(self.max_len)\n",
    "        src_mask[:src_length] = 1\n",
    "        tgt_mask[:tgt_length] = 1\n",
    "\n",
    "        return torch.LongTensor(src_ids), torch.LongTensor(tgt_ids), torch.LongTensor([src_length]), \\\n",
    "        torch.LongTensor([tgt_length]),  torch.BoolTensor(src_mask), torch.BoolTensor(tgt_mask), [src_words, tgt_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "### Question 1\n",
    "Before we build our model, we need to preprocess our data. \n",
    "Implement ``read_corpus`` function. \n",
    "### Quesiton 2\n",
    "Implement ``build_i2w`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair = namedtuple('Pair', ['src','tgt'])\n",
    "\n",
    "\n",
    "def read_corpus(data_path):\n",
    "    '''\n",
    "    param: \n",
    "    data_path: str --- path to the data file\n",
    "\n",
    "    return: \n",
    "    src: list[str] --- contains the source language sentences; each sentence is a string;\n",
    "    tgt: list[str] --- contains the target language sentences; each sentence is a string;\n",
    "    src_vocab: set(str) --- contains all the source language words appearing in the data file; each word is a string;\n",
    "    src_tgt: set(str) --- --- contains all the target language words appearing in the data file; each word is a string;\n",
    "\n",
    "    '''\n",
    "    with open(data_path, 'r', encoding='utf-8') as d:\n",
    "        data = d.readlines()\n",
    "        src, tgt = [], []\n",
    "        src_vocab, tgt_vocab = set(), set()\n",
    "\n",
    "        # 'data' is a list of strings; each element of this list represents a sentence which ended with \"\\n\" .\n",
    "        # Source language sentence (French) and target language sentence (English) are split by \"\\t\"\n",
    "        # Don't forget to remove the special \"\\n\" symbol of each sentence string\n",
    "        \n",
    "        # Your code here\n",
    "        \n",
    "        # End of your code\n",
    "        assert len(src) == len(tgt)\n",
    "        return src, tgt, src_vocab, tgt_vocab\n",
    "\n",
    "def lang_pairs(src, tgt):\n",
    "    pairs = []\n",
    "    for s,t in zip(src, tgt):\n",
    "        pairs.append(Pair(src=s, tgt=t))\n",
    "    return pairs\n",
    "\n",
    "def build_w2i(vocab):\n",
    "\n",
    "    w2i = {}\n",
    "    for i, w in enumerate(vocab):\n",
    "        w2i[w] = i\n",
    "    w2i[START_TOKEN] = len(w2i)\n",
    "    w2i[STOP_TOKEN] = len(w2i)\n",
    "    w2i[UNK_TOKEN] = len(w2i)\n",
    "    w2i[PAD_TOKEN] = len(w2i)\n",
    "\n",
    "    return w2i \n",
    "\n",
    "def build_i2w(w2i):\n",
    "    '''\n",
    "    param: \n",
    "    w2i: dict(word:idx) --- a dictionary in which the keys are words and the values are corresponding indices. \n",
    "                            E.g. w2i={'I':0,'love':1,'apple':2}\n",
    "    return \n",
    "    i2w: dict(idx: word) --- a dictionary in which the keys are the indices and the values are corresponding words. \n",
    "                             E.g. i2w = {0:'I',1:'love',2:'apple'}\n",
    "    '''\n",
    "    i2w = {}\n",
    "    ## YOUR CODE HERE (~2 lines)\n",
    "    \n",
    "    ### END OF YOUR CODE\n",
    "    return i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src, train_tgt, src_vocab, tgt_vocab = read_corpus(r'data/part2/train')\n",
    "dev_src, dev_tgt, _, _ = read_corpus(r'data/part2/dev')\n",
    "test_src, test_tgt, _, _ = read_corpus(r'data/part2/test')\n",
    "\n",
    "train_sent_pairs = lang_pairs(train_src,train_tgt)\n",
    "dev_sent_pairs = lang_pairs(dev_src,dev_tgt)\n",
    "test_sent_pairs = lang_pairs(test_src,test_tgt)\n",
    "\n",
    "fr_w2i = build_w2i(src_vocab)\n",
    "en_w2i = build_w2i(tgt_vocab)\n",
    "en_i2w = build_i2w(en_w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(src_vocab), len(tgt_vocab), len(train_src), len(train_tgt))\n",
    "print(len(fr_w2i), len(en_w2i), len(en_i2w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src[0], train_tgt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "### Question 3\n",
    " Implement part of the ``__init__`` function in ``Encoder`` class and ``Decoder`` class.\n",
    " \n",
    "### Question 4\n",
    "Implement the ``forward`` function in ``Encoder`` class . \n",
    "This function converts source sentences into word embedding tensors $X$,\n",
    "generates $h_1^{enc},h_2^{enc},...,h_m^{enc}$ and \n",
    "computes initial hidden state $h_0^{dec}$, and initial cell state $c_0^{dec}$.\n",
    "\n",
    "### Question 5\n",
    "Implement the ``forward`` function in ``Decoder`` class. \n",
    "This function constructs $\\bar{y}_t$ and runs the ``decode_one_step`` function \n",
    "over every time step of the input sentence.\n",
    "\n",
    "### Question  6 \n",
    "Implement ``decode_one_step`` function in ``Decoder`` class. \n",
    "This function applies the decoder's LSTM Cell for a \n",
    "single time step, computing the encoding of the target word $h_t^{dec}$, \n",
    "the attention distribution $\\alpha_t$, attention output\n",
    "$a_t$ and the combined output $o_t$.\n",
    "\n",
    "### Question 7\n",
    "Implement ``get_attn_weights`` function in ``Decoder`` class. \n",
    "This function will generate attention distribution $\\alpha_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeamNode = namedtuple('BeamNode',['prev_node', 'prev_hidden','prev_o_t', 'wordID', 'score', 'length'])\n",
    "Translation = namedtuple('Translation',['sent', 'score'])\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = encoder_config['hidden_size']\n",
    "        self.num_layers = encoder_config['num_layers']\n",
    "        self.bidir = encoder_config['bidirectional']\n",
    "        self.vocab_size = encoder_config['vocab_size']\n",
    "        self.emb_size = encoder_config['emb_size']\n",
    "        self.src_emb_matrix = encoder_config['src_embedding']\n",
    "\n",
    "        self.scr_embedding = None\n",
    "        self.W_h = None\n",
    "        self.W_c = None\n",
    "\n",
    "        ### TODO Initialize variables:\n",
    "        #               self.scr_embedding: Embedding layer for source language\n",
    "        #               self.W_h: Linear layer without bias (W_h describled in the PDF)\n",
    "        #               self.W_c: Linear layer without bias (W_c described in the PDF)\n",
    "        #\n",
    "        #   You need to use nn.Embedding function and two variables we have initialized for you.\n",
    "        #   You need to use nn.Linear function and one variable we have initialized for you.\n",
    "        #   For the use of nn.Embedding function, please refer to https://pytorch.org/docs/stable/nn.html#torch.nn.embedding\n",
    "        #   For the use of nn.Linear function, please refer to https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
    "        #   In nn.Linear function, the matrix multiplication is a transposed version of the Eq.(1) in description PDF.\n",
    "        \n",
    "        ### YOUR CODE HERE (3 lines)\n",
    "        \n",
    "        ### END OF YOUR CODE\n",
    "\n",
    "        if self.src_emb_matrix is not None:\n",
    "            self.src_embedding.weight.data.copy_(torch.FloatTensor(self.src_emb_matrix))\n",
    "            self.src_embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size = self.emb_size,\n",
    "                           hidden_size = self.hidden_size,\n",
    "                           num_layers = self.num_layers,\n",
    "                           bidirectional = self.bidir,\n",
    "                           batch_first  = True)\n",
    "\n",
    "    def forward(self, src_ids, src_length):\n",
    "        '''\n",
    "        params:\n",
    "            src_ids: torch.LongTensor of shape (batch_size, max_len) \n",
    "            src_length: torch.LongTensor of shape (batch_size,) contains the actual length of each sentence in the batch\n",
    "        return:\n",
    "            encoder_hiddens: torch.FloatTensor of shape(batch_size, max_len_in_batch, 2*hidden_size); the hidden states produced by Bi-LSTM\n",
    "            decoder_init: tuple(last_hidden, last_cell); last_hidden: torch.FloatTensorof shape (batch_size, 2*hidden_size); \n",
    "                                                        last_cell: torch.FloatTensor of shape(batch_size, 2*hidden_size); \n",
    "                                                        they are h_0^{dec},c_0^{dec} in our description PDF \n",
    "        '''\n",
    "\n",
    "        encoder_hiddens, decoder_init = None, None\n",
    "        src_length = torch.as_tensor(src_length, dtype=torch.int64, device='cpu').squeeze(1)\n",
    "\n",
    "        ### TODO:\n",
    "        ###     1. feed the \"src_ids\" into the src embedding layer to get a tensor X of shape (batch_size, max_len, emb_size)\n",
    "        ###     2. apply \"pack_padded_sequence\" function to X to get a new tensor X_packed\n",
    "        ###        (tip: set batch_first=True, enforced_sorted=False in the pack_padded_sequence function)\n",
    "        ###     3. use Bi-LSTM (rnn) to encode  \"X_packed\" to get \"encoder_hiddens\", \"last_hidden\", \"last_cell\"\n",
    "        ###     4. apply \"pad_packed_sequence\" to encoder_hiddens (remember to set batch_first=True); \n",
    "        ###     5. note that last_hidden/last_cell is of shape (2, batch_size, hidden_size); \n",
    "        ###        we want a shape of (batch_size, 2*hidden_size)\n",
    "        ###     6. apply linear transformation W_h, W_c to last_hidden/last cell to get the initial decoder hidden state\n",
    "        ###        (batch_size, hidden_size) and initial decoder cell state (batch_size, hidden_size).\n",
    "        ### You may use these functions in your implemetation:\n",
    "        ###     pack_padded_sequence: https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence\n",
    "        ###     pad_packed_sequence: https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_packed_sequence\n",
    "        ###     torch.cat: https://pytorch.org/docs/stable/torch.html#torch.cat\n",
    "\n",
    "        ### YOUR CODE HERE (~ 9 lines)\n",
    "        \n",
    "        ### END OF YOUR CODE\n",
    "        return encoder_hiddens, decoder_init\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_config):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_size = decoder_config['hidden_size']\n",
    "        self.vocab_size = decoder_config['vocab_size']\n",
    "        self.emb_size = decoder_config['emb_size']\n",
    "        self.tgt_emb_matrix = decoder_config['tgt_embedding']\n",
    "\n",
    "        self.rnn = None\n",
    "        self.W_attn = None\n",
    "        self.W_u = None\n",
    "        self.tgt_embedding = None\n",
    "\n",
    "        ### TODO Initialize variables: \n",
    "        #               self.tgt_embedding: nn.Embedding layer for source language; You need to use nn.Embedding function \n",
    "        #                                  and 2 variables we have initialized for you.\n",
    "        #               self.rnn: nn.LSTMCell ; You need to use nn.LSTMCell function and 2 variables we have initialized for you. \n",
    "        #               self.W_attn: nn.Linear layer without bias (W_attn describled in the PDF); \n",
    "        #                            You need to use nn.Linear function and 1 variable we have initialized for you.\n",
    "        #               self.W_u: nn.Linear layer without bias (W_attn describled in the PDF)\n",
    "\n",
    "        # For the use of nn.Embedding function, please refer to https://pytorch.org/docs/stable/nn.html#\n",
    "        # For the use of nn.Linear function, please refer to https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
    "        # In nn.Linear function, the matrix multiplication is a transposed version of the Eq.(1) in description PDF.\n",
    "        # For the use of nn.LSTMCell function, please refer to https://pytorch.org/docs/stable/nn.html#lstmcell\n",
    "        # Think about the shape of \\bar{y}_t in the description PDF when initializing self.rnn with nn.LSTMCell\n",
    "\n",
    "        ### YOUR CODE HERE (4 lines)\n",
    "        \n",
    "        ### END OF YOUR CODE\n",
    "\n",
    "        if self.tgt_emb_matrix is not None:\n",
    "            self.tgt_embedding.weight.data.copy_(torch.Tensor(self.tgt_emb_matrix))\n",
    "            self.tgt_embedding.weight.requires_grad = True        \n",
    "\n",
    "    def forward(self, tgt_ids, tgt_lengths, encoder_hiddens, encoder_hidden_masks, decoder_init):\n",
    "        '''\n",
    "        params:\n",
    "            tgt_ids: torch.LongTensor of shape (batch_size, max_len); each element is a number specifying the position of\n",
    "                    a word in a embedding matrix\n",
    "            tgt_lengths: torch.LongTensor of shape (batch_size,) contains the actual length of each sentence in the batch\n",
    "            encoder_hiddens: torch.FloatTensosr of shape ( batch_size, max_len_in_batch, 2*hidden_size); \n",
    "                                \"max_len_in_batch\" is the max length in a batch. It is less than \"max_len\".\n",
    "            encoder_hidden_masks: torch.BoolTensor of shape (batch_size, max_len), specifying which positions are pad tokens.\n",
    "            decoder_init: tuple(h_0, c_0); the output \"decoder_init\" of the encoder; \n",
    "                            h_0 of shape (batch_size, hidden_size), c_0 of shape (batch_size, hidden_size)\n",
    "        return:\n",
    "            combined_outputs: torch.FloatTensor of shape (max_len_batch, batch_size, hidden_size)\n",
    "        '''\n",
    "        \n",
    "        decoder_state = decoder_init\n",
    "        max_len_batch = torch.max(tgt_lengths) -1               # don't consider the end token\n",
    "        batch_size = encoder_hiddens.size()[0]\n",
    "        o_prev = torch.zeros(batch_size, self.hidden_size, device='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        combined_outputs = []\n",
    "        \n",
    "        ### TODO:\n",
    "        ###     1. feed the \"tgt_ids\" into the embedding layer to get a tensor \"Y\" of shape (batch_size, max_len, emb_size)\n",
    "        ###     2. construct a for loop with range 0:max_len_batch\n",
    "        ###         within the for loop: \n",
    "        ###                         1). slice Y by indexing; you should have y_t of shape (batch_size, emb_size)\n",
    "        ###                         2). concatenate y_t with o_prev , yielding ybar_t as described in the PDF\n",
    "        ###                         3). feed ybar_t and \"decoder state\", \"encoder_hiddens\", \"encoder_hidden_masks\" into function \"decode_one_step()\"\n",
    "        ###                             and it will output new \"decoder_state\" (a tuple), new \"o_t\" \n",
    "        ###                         4). append new \"o_t\" to \"combined_outputs\"\n",
    "        ###                         5). update \"o_prev\" with new \"o_t\"\n",
    "        ###     3. use \"torch.stack\" function to process combined_outputs (a list of tensors; each tensor of shape (batch_size, hidden_size)) to \n",
    "        ###          a single tensor of shape (max_len_batch, batch_size, hidden_size)\n",
    "        ###\n",
    "        ### You may use these functions in your implementation:\n",
    "        ###     torch.cat: https://pytorch.org/docs/stable/torch.html#torch.cat\n",
    "        ###     torch.stack: https://pytorch.org/docs/stable/torch.html#torch.stack\n",
    "        ### YOUR CODE HERE (~ 8 lines)\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "        return combined_outputs       \n",
    "            \n",
    "    def decode_one_step(self, ybar_t, decoder_state, encoder_hiddens, encoder_hidden_masks):\n",
    "        '''\n",
    "        param:\n",
    "            ybar_t: torch.FloatTensor of shape (batch_size, emb_size + hidden_size)\n",
    "            decoder_state: tuple(h_t, c_t); h_t of shape (batch_size, hidden_size); c_t of shape (batch_size, hidden_size);\n",
    "            encoder_hiddens: torch.FloatTensosr of shape ( batch_size, max_len_in_batch, 2*hidden_size); \"max_len_in_batch\" is the max length in a batch. It is less than \"max_len\".\n",
    "            encoder_hidden_masks: torch.BoolTensor of shape (batch_size, max_len), specifying which positions are pad tokens.\n",
    "        return: \n",
    "            decoder_state: tuple(h_t, c_t); both h_t and c_t have a shape (batch_size, hidden_size)\n",
    "            o_t: torch.FloatTensor of shape (batch_size, hidden_size)\n",
    "        '''\n",
    "        ### TODO:\n",
    "        ###     1. Apply the decoder (self.rnn) to \"ybar_t\", \"decoder_state\", yielding a new \"decoder_state\"\n",
    "        ###     2. split the decoder state into two parts, \"h\" and \"c\"; h has a shape (batch_size, hidden_size); c has a shape (batch_size, hidden_size)\n",
    "        ###     3. apply \"get_attn_weight()\" function to \"h\", \"encoder_hiddens\", \"encoder_hidden_masks\", yielding attention weights (alpha_t in the PDF) of shape (batch_size, max_len_in_batch)\n",
    "        ###     4. apply torch.bmm function to alpha_t and \"encoder_hiddens\", yielding the \"a_t\" in PDF. \n",
    "        ###        You also need to use \"unsqueeze\" and \"squeeze\" function here. Be sure to specify the \"dim\" parameter in these two functions. \n",
    "        ###        \"a_t\" has a shape (batch_size, 2*hidden_size)\n",
    "        ###     5. concatenate \"a_t\" and \"h\", yielding \"u_t\" in the PDF; \"u_t\" has a shape (batch_size, 3*hidden_size)\n",
    "        ###     6. apply linear transformation W_u and \"torch.tanh\" function to \"u_t\", yielding \"o_t\" of shape (batch_size, hidden_size)\n",
    "\n",
    "        ### You may use these functions in your implementation:\n",
    "        ###     torch.cat: https://pytorch.org/docs/stable/torch.html#torch.cat\n",
    "        ###     torch.bmm: https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
    "        ###     torch.tanh: https://pytorch.org/docs/stable/torch.html#torch.tanh\n",
    "        ###     torch.squeeze: https://pytorch.org/docs/stable/torch.html#torch.squeeze\n",
    "        ###     torch.unsqueeze: https://pytorch.org/docs/stable/torch.html#torch.unsqueeze\n",
    "\n",
    "        ### YOUR CODE HERE (~6 lines)\n",
    "        \n",
    "        ## END OF YOUR CODE\n",
    "        return decoder_state, o_t\n",
    "        \n",
    "    def get_attn_weights(self, h, encoder_hiddens, encoder_hidden_masks):\n",
    "        '''\n",
    "        compute the attention weights \\alpha_t in the PDF\n",
    "        param:\n",
    "            h: torch.FloatTensor of shape (batch_size, hidden_size)\n",
    "            encoder_hiddens: torch.FloatTensosr of shape ( batch_size, max_len_in_batch, 2*hidden_size); \"max_len_in_batch\" is the max length in a batch. It is less than \"max_len\".\n",
    "            encoder_hidden_masks: torch.BoolTensor of shape (batch_size, max_len), specifying which positions are pad tokens. False -- pad token; True -- not pad token\n",
    "        return:\n",
    "            attn_weights: torch.FloatTensor of shape (batch_size, max_len_in_batch)\n",
    "        '''\n",
    "\n",
    "        h = h.unsqueeze(-1)                 ### (batch_size, hidden_size, 1)\n",
    "        max_len_in_batch = encoder_hiddens.size()[1]\n",
    "\n",
    "        ### TODO:\n",
    "        ###     1. apply linear transformation \"W_attn\" to \"encoder_hiddens\"; the result has  a shape (batch_size, max_len_in_batch, hidden_size)\n",
    "        ###     2. apply torch.bmm to the result of step 1 and \"h\", yielding score e_t of shape (batch_size, max_len_in_batch, 1);\n",
    "        ###        squeeze e_t in the last dimension\n",
    "        ###     3. apply torch.Tensor.masked_fill_() function to \"e_t\"; the parameters of this function are Bool tensor \"encoder_hidden_masks\" and a constant \"-float('inf')\";\n",
    "        ###        before \"torch.Tensor.masked_fill_()\" function, this \"encoder_hidden_masks\" should be sliced to have a shape (batch_size, max_len_in_batch) (Only the first max_len_in_batch columns will be kept)\n",
    "        ###     4. apply \"F.softmax()\" function to \"e_t\", yielding \"alpha_t\" of shape (batch_size, max_len_in_batch)\n",
    "\n",
    "        ### You may use these functions in your implementation:\n",
    "        ###     torch.bmm: https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
    "        ###     torch.squeeze: https://pytorch.org/docs/stable/torch.html#torch.squeeze\n",
    "        ###     torch.Tensor.masked_fill_: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.masked_fill_\n",
    "        ###     F.softmax: https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.softmax\n",
    "\n",
    "        ### YOUR CODE HERE (4~6 lines)\n",
    "        \n",
    "        ### END OF YOUR CODE\n",
    "        return attn_weights\n",
    "\n",
    "\n",
    "class NMT(nn.Module):\n",
    "    def __init__(self, encoder_config, decoder_config):\n",
    "        super(NMT, self).__init__()\n",
    "        self.encoder = Encoder(encoder_config)\n",
    "        self.decoder = Decoder(decoder_config)\n",
    "        self.encoder_config = encoder_config\n",
    "        self.decoder_config = decoder_config\n",
    "        self.W_v = nn.Linear(decoder_config['hidden_size'], decoder_config['vocab_size'])\n",
    "        \n",
    "    def forward(self, src_ids, src_lengths, src_masks, tgt_ids, tgt_lengths, tgt_masks):\n",
    "        # src_ids:(batch_size, max_len)\n",
    "        # src_lengths: (batch_size)\n",
    "        # src_mask: (batch_size, max_len)\n",
    "        # tgt_ids: (batch_size, max_len)\n",
    "        # tgt_lengths: (batch_size)\n",
    "        # tgt_masks: (batch_size, max_len)\n",
    "        \n",
    "        encoder_hiddens, decoder_init_hidden = self.encoder(src_ids, src_lengths)\n",
    "        outputs = self.decoder(tgt_ids, tgt_lengths, encoder_hiddens, src_masks, decoder_init_hidden)\n",
    "        tgt_unnormalized_score = self.W_v(outputs)\n",
    "        tgt_log_prob = F.log_softmax(tgt_unnormalized_score, dim=-1)\n",
    "        \n",
    "        max_len_batch = torch.max(tgt_lengths)\n",
    "        tgt_masks = tgt_masks[:, :max_len_batch].permute(1, 0) # (l,b)\n",
    "        tgt_ids = tgt_ids.permute(1,0)[:max_len_batch, :] #(l,b)\n",
    "        tgt_words_log_prob = torch.gather(tgt_log_prob, -1, tgt_ids[1:].unsqueeze(-1)).squeeze(-1) * tgt_masks[1:].float()\n",
    "        \n",
    "        tgt_sents_log_prob = torch.sum(tgt_words_log_prob, dim=0)\n",
    "        return tgt_sents_log_prob       #(b)\n",
    "\n",
    "    \n",
    "    def beam_search(self, src_ids, src_length, beam_size):\n",
    "        # src_ids: (batch_size, max_len)\n",
    "        # src_lengths: (1, 1)\n",
    "        # beam_size: int\n",
    "        \n",
    "        STOP_ID = self.decoder_config['en_w2i'][STOP_TOKEN]\n",
    "        max_decode_length = 30\n",
    "        encoder_hiddens, decoder_init_hidden = self.encoder(src_ids, src_length)\n",
    "        encoder_hidden_masks = torch.BoolTensor(np.ones((1,src_length.item()))).to(device)\n",
    "        \n",
    "        START_ID = self.decoder_config['en_w2i']['<s>']\n",
    "        prev_o_t = torch.zeros(1, self.decoder_config['hidden_size']).to(device)\n",
    "        input_beam_nodes = [BeamNode(prev_node=None, prev_hidden=decoder_init_hidden, prev_o_t=prev_o_t , wordID=START_ID, \n",
    "                            score=0, length=1)]\n",
    "\n",
    "        finished_beam = 0\n",
    "        end_beam = []\n",
    "        max_finished_beam = beam_size\n",
    "        while finished_beam < max_finished_beam and input_beam_nodes[0].length < max_decode_length:\n",
    "            cur_hidden = []\n",
    "            cur_o_t = []\n",
    "            prev_scores = []\n",
    "            cur_len = input_beam_nodes[0].length\n",
    "\n",
    "            for n in input_beam_nodes:\n",
    "                y_t = self.decoder.tgt_embedding(torch.LongTensor([n.wordID]).to(device))\n",
    "                y_t = torch.cat((y_t, n.prev_o_t), dim=1)\n",
    "\n",
    "                decoder_hidden, o_t = self.decoder.decode_one_step(y_t, n.prev_hidden, encoder_hiddens, encoder_hidden_masks)\n",
    "                cur_hidden.append(decoder_hidden)\n",
    "                cur_o_t.append(o_t)\n",
    "                prev_scores.append(n.score)\n",
    "            \n",
    "            o_t = torch.stack(cur_o_t, dim=0)\n",
    "            scores = self.W_v(o_t).squeeze(1)    ###(beam, vocab)\n",
    "            # print(scores.size(), torch.Tensor(prev_scores).size())\n",
    "            prev_scores = torch.Tensor(prev_scores).unsqueeze(-1).expand_as(scores).to(device)\n",
    "            \n",
    "            assert len(scores.size()) == 2\n",
    "            assert scores.size(0) == len(input_beam_nodes)\n",
    "            assert scores.size(1) == self.decoder_config['vocab_size']\n",
    "\n",
    "            log_prob = F.log_softmax(scores, dim=-1)\n",
    "            cur_score = (log_prob + prev_scores).view(-1)\n",
    "            topk_score, topk_pos = torch.topk(cur_score, beam_size)\n",
    "\n",
    "            node_ids = topk_pos // self.decoder_config['vocab_size']\n",
    "            word_ids = topk_pos % self.decoder_config['vocab_size']\n",
    "\n",
    "            next_nodes = []\n",
    "            for score, node_id, word_id in zip(topk_score, node_ids, word_ids):\n",
    "                score = score.item()\n",
    "                node_id = node_id.item()\n",
    "                word_id = word_id.item()\n",
    "\n",
    "                node = BeamNode(prev_node=input_beam_nodes[node_id], prev_hidden=cur_hidden[node_id], \n",
    "                                prev_o_t=cur_o_t[node_id] , score=score,\n",
    "                                wordID=word_id, length=cur_len+1)\n",
    "\n",
    "                if word_id == STOP_ID:\n",
    "                    beam_size -= 1\n",
    "                    end_beam.append(node)\n",
    "                    finished_beam += 1\n",
    "                else:\n",
    "                    next_nodes.append(node)\n",
    "            \n",
    "            input_beam_nodes = next_nodes\n",
    "            \n",
    "            if cur_len + 1 >= max_decode_length:\n",
    "                end_beam.extend(next_nodes)\n",
    "        \n",
    "        seqs = []\n",
    "        for n in end_beam:\n",
    "            seq = []\n",
    "            score = n.score\n",
    "            while True:\n",
    "                prev_node = n.prev_node\n",
    "                wordID = n.wordID\n",
    "                try:\n",
    "                    word = self.decoder_config['en_i2w'][wordID]\n",
    "                except KeyError:\n",
    "                    word = UNK_TOKEN\n",
    "                # print(word)\n",
    "                seq.append(word)\n",
    "                if prev_node.wordID == START_ID:\n",
    "                    break\n",
    "                n = prev_node\n",
    "            seqs.append(Translation(sent=seq[-1:0:-1], score=score))\n",
    "\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "def eval_ppl(model, dev_iter):\n",
    "    model.eval()\n",
    "    \n",
    "    cum_loss = 0.\n",
    "    cum_tgt_words = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dev_iter:\n",
    "            batch_data = tuple(t.to(device) for t in batch_data[:-1])\n",
    "            b_src_ids, b_tgt_ids, b_src_len, b_tgt_len, b_src_mask, b_tgt_mask = batch_data\n",
    "            batch_loss = -1 * model(b_src_ids, b_src_len, b_src_mask, b_tgt_ids, b_tgt_len, b_tgt_mask).sum()\n",
    "            cum_loss += batch_loss.item()\n",
    "            b_num_words = b_tgt_len.sum() - b_tgt_len.size(0)\n",
    "            cum_tgt_words += b_num_words\n",
    "        \n",
    "        ppl = np.exp(cum_loss/cum_tgt_words.item())\n",
    "        \n",
    "    model.train()\n",
    "    return ppl\n",
    "\n",
    "def compute_corpus_bleu_score(references, predictions):\n",
    "    # references: List[List[str]]\n",
    "    # prediction: Liset[List[str]]\n",
    "    return corpus_bleu([[ref] for ref in references], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, dev_iter, encoder_config, decoder_config, epoch):\n",
    "\n",
    "    model = NMT(encoder_config, decoder_config)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    best_eval_ppl = float('inf')\n",
    "    \n",
    "    for it in range(epoch):\n",
    "        total_train_loss = 0.\n",
    "        total_train_words = 0\n",
    "        \n",
    "        for batch_data in train_iter:\n",
    "            batch_data = tuple(t.to(device) for t in batch_data[:-1])\n",
    "            b_src_ids, b_tgt_ids, b_src_len, b_tgt_len, b_src_mask, b_tgt_mask = batch_data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_loss = -1 * model(b_src_ids, b_src_len, b_src_mask, b_tgt_ids, b_tgt_len, b_tgt_mask).sum()\n",
    "            loss = batch_loss / batch_size\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += batch_loss.item()\n",
    "            total_train_words += b_tgt_len.sum() - b_tgt_len.size(0)\n",
    "            # print(b_tgt_len, b_tgt_len.size())\n",
    "            \n",
    "        print('train_loss:{}, train_ppl:{} '.format(total_train_loss/batch_size, np.exp(total_train_loss/total_train_words.item())))\n",
    "        \n",
    "        e_ppl = eval_ppl(model, dev_iter)\n",
    "        if e_ppl < best_eval_ppl:\n",
    "            print('better model found!')   \n",
    "            print('eval_ppl:', e_ppl)\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            best_eval_ppl = e_ppl\n",
    "\n",
    "def test(model, test_iter):\n",
    "    # support only batch_size = 1\n",
    "    model.eval()\n",
    "    corpus_reference = []\n",
    "    corpus_prediction = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_iter:\n",
    "            raw_sent = batch_data[-1]\n",
    "            # print(raw_sent)\n",
    "            batch_data = tuple(t.to(device) for t in batch_data[:-1])\n",
    "            b_src_ids, b_tgt_ids, b_src_len, b_tgt_len, b_src_mask, b_tgt_mask = batch_data\n",
    "            seqs = model.beam_search(b_src_ids, b_src_len, 2)\n",
    "            ref = [i[0] for i in raw_sent[1]]\n",
    "            corpus_reference.append(ref)\n",
    "            sorted_seqs = sorted(seqs, key=lambda x: x.score, reverse=True)\n",
    "            corpus_prediction.append(sorted_seqs[0].sent)\n",
    "        print(len(corpus_prediction),corpus_prediction)\n",
    "        print(len(corpus_reference), corpus_reference)\n",
    "        bleu = compute_corpus_bleu_score(corpus_reference, corpus_prediction)\n",
    "        print('BLEU score on Test set:{}'.format(bleu))\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_emb = None\n",
    "en_emb = None\n",
    "\n",
    "encoder_config = {'hidden_size': 256, \n",
    "                      'num_layers': 1, \n",
    "                      'bidirectional':True,\n",
    "                      'vocab_size':  len(fr_w2i),\n",
    "                      'emb_size':300, \n",
    "                      'src_embedding': fr_emb}\n",
    "decoder_config = {'hidden_size': 256,\n",
    "                      'vocab_size': len(en_w2i),\n",
    "                      'emb_size': 300, \n",
    "                      'tgt_embedding': en_emb,\n",
    "                      'en_w2i':en_w2i,\n",
    "                      'en_i2w':en_i2w}\n",
    "max_len = 30\n",
    "batch_size = 32\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "train_dataset = TranslationDataset(train_sent_pairs, fr_w2i, en_w2i, tokenizer, max_len)\n",
    "dev_dataset = TranslationDataset(dev_sent_pairs, fr_w2i, en_w2i, tokenizer, max_len)\n",
    "test_dataset = TranslationDataset(test_sent_pairs, fr_w2i, en_w2i, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
    "epoch = 8\n",
    "\n",
    "train(train_loader, dev_loader, encoder_config, decoder_config, epoch)\n",
    "model = NMT(encoder_config, decoder_config)\n",
    "model.load_state_dict(torch.load(r'best_model.pt'))\n",
    "model = model.to(device)\n",
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
