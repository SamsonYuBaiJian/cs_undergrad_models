{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AI homework 1 - torch intro",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch - homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR",
        "colab_type": "text"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpzFaX0J6Zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7fe31c6-448c-4af1-c873-ed41827803d0"
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1002819\"\n",
        "student_name=\"Samson Yu Bai Jian\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Samson Yu Bai Jian, number: 1002819\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_",
        "colab_type": "text"
      },
      "source": [
        " ## Question 1 -- matrix multiplication\n",
        "\n",
        "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
        "\n",
        "a) which type of GPU card you have and \n",
        "\n",
        "b) show the computation time for both CPU and GPU (using PyTorch). \n",
        "\n",
        "c) How much % fast is the GPU? \n",
        "\n",
        " The operation to implement is the dot product $C = B * A^T$\n",
        "\n",
        " whereby $A$ is a random matrix of size $30,000 \\times 1000$ and $B$ is a random matrix of size $3000 \\times 1000$. In addition to the required information asked above:\n",
        " \n",
        " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINvhm-PLKak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "290a7013-b802-4c34-d0e7-be493307301b"
      },
      "source": [
        "# implement solution here\n",
        "# a)\n",
        "!nvidia-smi\n",
        "print(\"\\n\")\n",
        "\n",
        "# b)\n",
        "import torch\n",
        "import timeit\n",
        "\n",
        "B = torch.rand(30000, 1000)\n",
        "A = torch.rand(3000, 1000)\n",
        "B_gpu = B.cuda()\n",
        "A_gpu = A.cuda()\n",
        "\n",
        "num_runs = 3\n",
        "\n",
        "cpu_duration = timeit.timeit('B.mm(A.T)', number=num_runs, globals=globals())\n",
        "C = B.mm(A.T)\n",
        "print(\"C for CPU is \" + str(C))\n",
        "print(\"C for CPU is calculated in \" + str(cpu_duration / num_runs) + \" seconds from the average of \" + str(num_runs) + \" runs.\")\n",
        "\n",
        "gpu_duration = timeit.timeit('B_gpu.mm(A_gpu.T)', number=num_runs, globals=globals())\n",
        "C_gpu = B_gpu.mm(A_gpu.T)\n",
        "print(\"C for GPU is \" + str(C_gpu))\n",
        "print(\"C for GPU is calculated in \" + str(gpu_duration / num_runs) + \" seconds from the average of \" + str(num_runs) + \" runs.\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# c)\n",
        "print(\"GPU is \" + str(cpu_duration / gpu_duration) + \"% fast.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 26 06:13:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "C for CPU is tensor([[257.6898, 249.6010, 255.0111,  ..., 253.2571, 231.7746, 251.0414],\n",
            "        [260.5560, 254.7230, 258.5290,  ..., 264.9998, 237.6189, 251.1279],\n",
            "        [267.2371, 254.5237, 263.7058,  ..., 259.7960, 241.9147, 261.4051],\n",
            "        ...,\n",
            "        [252.0231, 250.8906, 252.7767,  ..., 251.4981, 225.5653, 246.4519],\n",
            "        [260.0795, 248.5555, 261.9846,  ..., 255.5184, 237.6695, 256.1788],\n",
            "        [257.6772, 251.6110, 251.6531,  ..., 252.3783, 237.0908, 253.0704]])\n",
            "C for CPU is calculated in 2.491996093999996 seconds from the average of 3 runs.\n",
            "C for GPU is tensor([[257.6899, 249.6010, 255.0110,  ..., 253.2571, 231.7746, 251.0414],\n",
            "        [260.5559, 254.7231, 258.5289,  ..., 264.9995, 237.6190, 251.1279],\n",
            "        [267.2371, 254.5238, 263.7058,  ..., 259.7960, 241.9145, 261.4052],\n",
            "        ...,\n",
            "        [252.0231, 250.8906, 252.7769,  ..., 251.4982, 225.5654, 246.4518],\n",
            "        [260.0796, 248.5553, 261.9844,  ..., 255.5183, 237.6697, 256.1788],\n",
            "        [257.6773, 251.6109, 251.6531,  ..., 252.3784, 237.0909, 253.0705]],\n",
            "       device='cuda:0')\n",
            "C for GPU is calculated in 0.0009601916666639454 seconds from the average of 3 runs.\n",
            "\n",
            "\n",
            "GPU is 2595.311103519671% fast.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJXmfT-yU3g",
        "colab_type": "text"
      },
      "source": [
        "## Question 2 - grad\n",
        "\n",
        "\n",
        "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
        "\n",
        "Let  $w=[w_1,w_2]^T$\n",
        "\n",
        "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
        "\n",
        "a) In PyTorch, compute:   $\\Delta_w g(w)$ \n",
        "\n",
        " and verify that $\\Delta_w g([\\pi,1])=[2,2\\piâˆ’1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
        "\n",
        "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this is a second function below to verify that it comes to the same solution. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLjz6_LKt4sc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f9e8884a-51eb-4346-a92c-09ab7ba14713"
      },
      "source": [
        "# write your solution here\n",
        "# a)\n",
        "import numpy as np\n",
        "\n",
        "def g(w):\n",
        "    return 2 * w[0] * w[1] + w[1] * torch.cos(w[0])\n",
        "\n",
        "x = torch.tensor(np.pi, requires_grad=True)\n",
        "y = torch.tensor(1., requires_grad=True)\n",
        "z = g([x, y])\n",
        "z.backward()\n",
        "print(\"PyTorch grad function calculations: \", [x.grad.item(), y.grad.item()])\n",
        "\n",
        "# b)\n",
        "def manual_dg(w):\n",
        "    return [2 * w[1] - w[1] * torch.sin(w[0]), 2 * w[0] + torch.cos(w[0])]\n",
        "dg = manual_dg([x, y])\n",
        "print(\"Manual calculations: \", [dg[0].item(), dg[1].item()])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch grad function calculations:  [2.0, 5.2831854820251465]\n",
            "Manual calculations:  [2.0, 5.2831854820251465]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwP6ur8LKjD",
        "colab_type": "text"
      },
      "source": [
        "## Question 3 - dance hit song prediction\n",
        "\n",
        "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
        "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
        " * Target variable: Topclass1030: \n",
        "   * 1 means it was a top 10 hit song; \n",
        "   * 0 means it never went above top 30 position.\n",
        "\n",
        "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
        "\n",
        "Print the evolution of the loss every few epochs and train the model until it converges. \n",
        " \n",
        " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
        " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyRP6bl8t4Wc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "e90f2197-85da-4bc8-a478-6b99a55ebf28"
      },
      "source": [
        "# Your code here\n",
        "\n",
        "# load data\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv')\n",
        "labels = train.iloc[:,-1]\n",
        "train = train.drop('Topclass1030', axis=1)\n",
        "traindata = torch.Tensor(train.values)\n",
        "trainlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "# define logistic regression model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  # input_size: Dimensionality of input feature vector.\n",
        "  # num_classes: The number of classes in the classification problem.\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    # Always call the superclass (nn.Module) constructor first!\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    # Set up the linear transform\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Apply the linear transform.\n",
        "    # out is of shape (batch_size, num_classes). \n",
        "    out = self.linear(x)\n",
        "    out = torch.sigmoid(out)\n",
        "    # Softmax the out tensor to get a log-probability distribution\n",
        "    # over classes for each example.\n",
        "    return out\n",
        "\n",
        "# train model\n",
        "# Binary classifiation\n",
        "num_outputs = 1\n",
        "num_input_features = train.shape[1]\n",
        "\n",
        "# Create the logistic regression model\n",
        "logreg_clf = LogisticRegression(num_input_features, num_outputs)\n",
        "\n",
        "print_every = 5\n",
        "lr_rate = 0.001\n",
        "criterion = nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(logreg_clf.parameters(), lr=lr_rate)\n",
        "prev_loss = 1e10\n",
        "epoch = 200\n",
        "\n",
        "# train till convergence\n",
        "for i in range(epoch):\n",
        "    for j in range(traindata.size()[0]):\n",
        "        Xtrain = torch.Tensor(traindata[j])\n",
        "        y_var = torch.Tensor([labels[j]]).unsqueeze(0)\n",
        "        y_hat = logreg_clf(Xtrain)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(y_hat, y_var)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if i % print_every == 0:\n",
        "        print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.data.numpy()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.34890156984329224, \n",
            "Epoch: 5, Loss: 0.45001208782196045, \n",
            "Epoch: 10, Loss: 0.48037290573120117, \n",
            "Epoch: 15, Loss: 0.4771309792995453, \n",
            "Epoch: 20, Loss: 0.46074485778808594, \n",
            "Epoch: 25, Loss: 0.4417151212692261, \n",
            "Epoch: 30, Loss: 0.42400845885276794, \n",
            "Epoch: 35, Loss: 0.4087331295013428, \n",
            "Epoch: 40, Loss: 0.39593037962913513, \n",
            "Epoch: 45, Loss: 0.38530394434928894, \n",
            "Epoch: 50, Loss: 0.3764950931072235, \n",
            "Epoch: 55, Loss: 0.36917564272880554, \n",
            "Epoch: 60, Loss: 0.36307042837142944, \n",
            "Epoch: 65, Loss: 0.3579563498497009, \n",
            "Epoch: 70, Loss: 0.35365596413612366, \n",
            "Epoch: 75, Loss: 0.35002845525741577, \n",
            "Epoch: 80, Loss: 0.3469603359699249, \n",
            "Epoch: 85, Loss: 0.3443610668182373, \n",
            "Epoch: 90, Loss: 0.3421575427055359, \n",
            "Epoch: 95, Loss: 0.34029191732406616, \n",
            "Epoch: 100, Loss: 0.3387138545513153, \n",
            "Epoch: 105, Loss: 0.33738452196121216, \n",
            "Epoch: 110, Loss: 0.33626946806907654, \n",
            "Epoch: 115, Loss: 0.3353404700756073, \n",
            "Epoch: 120, Loss: 0.3345751166343689, \n",
            "Epoch: 125, Loss: 0.3339524567127228, \n",
            "Epoch: 130, Loss: 0.3334561586380005, \n",
            "Epoch: 135, Loss: 0.33307114243507385, \n",
            "Epoch: 140, Loss: 0.3327855169773102, \n",
            "Epoch: 145, Loss: 0.33258599042892456, \n",
            "Epoch: 150, Loss: 0.3324659764766693, \n",
            "Epoch: 155, Loss: 0.33241477608680725, \n",
            "Epoch: 160, Loss: 0.3324262499809265, \n",
            "Epoch: 165, Loss: 0.3324935734272003, \n",
            "Epoch: 170, Loss: 0.3326110243797302, \n",
            "Epoch: 175, Loss: 0.3327728807926178, \n",
            "Epoch: 180, Loss: 0.3329750895500183, \n",
            "Epoch: 185, Loss: 0.3332138657569885, \n",
            "Epoch: 190, Loss: 0.333484947681427, \n",
            "Epoch: 195, Loss: 0.33378517627716064, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4yfGoGuChe",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to test the accuracy of your model on the training set: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L88WmKtMt5gH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "80315172-ffdb-4156-b25c-c75bf2157138"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "# test = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "test = pd.read_csv('https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv')\n",
        "labels = test.iloc[:,-1]\n",
        "test = test.drop('Topclass1030', axis=1)\n",
        "testdata = torch.Tensor(test.values)\n",
        "testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for i in range(0, testdata.size()[0]): \n",
        "  # print(testdata[i].size())\n",
        "  Xtest = torch.Tensor(testdata[i])\n",
        "  y_hat = logreg_clf(Xtest)\n",
        "  \n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  if (prediction == testlabels[i]):\n",
        "    if (prediction == 1):\n",
        "      TP += 1\n",
        "    else: \n",
        "      TN += 1\n",
        "\n",
        "  else:\n",
        "    if (prediction == 1):\n",
        "      FP += 1\n",
        "    else: \n",
        "      FN += 1\n",
        "\n",
        "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "rate = TP/(FN+TP)\n",
        "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 39, True Negatives: 20\n",
            "False Positives: 9, False Negatives: 11\n",
            "Class specific accuracy of correctly predicting a hit song is 0.78\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}