{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function that estimates the emission parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"\n",
    "    For loading a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (string): File path of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    list: List of strings of each line in the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(file_path) as file:\n",
    "        data = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# TODO: load your training dataset\n",
    "\n",
    "al = load_dataset('dataset/al/AL/train')\n",
    "cn = load_dataset('dataset/cn/CN/train')\n",
    "en = load_dataset('dataset/en/EN/train')\n",
    "sg = load_dataset('dataset/sg/SG/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_parameters(train_data, k=3, token='#UNK#'):\n",
    "    \"\"\"\n",
    "    For getting emission parameters for a training dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    train_data (list): Data loaded from your training data with the \"load_dataset\" function\n",
    "    k (int): Word frequency threshold (default 3)\n",
    "    token (string): Token representing words that appear less than the frequency threshold (default #UNK#)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of emission parameters, with format {word:{tag:count}}\n",
    "    \n",
    "    \"\"\"\n",
    "    assert type(k) == int\n",
    "    assert train_data != None\n",
    "    \n",
    "    emission_dict = {}\n",
    "    x_count = {}\n",
    "    y_count = {}\n",
    "    \n",
    "    # get word count for each word in the training dataset\n",
    "    for d in train_data:\n",
    "        d = d.strip('\\n').split(' ')\n",
    "        try:\n",
    "            x = d[0]\n",
    "            y = d[1]\n",
    "        except:\n",
    "            continue\n",
    "        if x not in x_count.keys():\n",
    "            x_count[x] = 1\n",
    "        else:\n",
    "            x_count[x] += 1\n",
    "        if y not in y_count.keys():\n",
    "            y_count[y] = 1\n",
    "        else:\n",
    "            y_count[y] += 1\n",
    "            \n",
    "    # process data\n",
    "    for d in train_data:\n",
    "        d = d.strip('\\n').split(' ')\n",
    "        try:\n",
    "            x = d[0]\n",
    "            y = d[1]\n",
    "        except:\n",
    "            continue\n",
    "        # add emission paramters for word if word appears more than frequency k\n",
    "        if x_count[x] >= k:\n",
    "            if x not in emission_dict.keys():\n",
    "                emission_dict[x] = {y:1}\n",
    "            elif y not in emission_dict[x].keys():\n",
    "                emission_dict[x][y] = 1\n",
    "            else:\n",
    "                emission_dict[x][y] += 1\n",
    "        # change word to unknown token and add emission paramters if word does not appear more than frequency k\n",
    "        elif x_count[x] < k:\n",
    "            if token not in emission_dict.keys():\n",
    "                emission_dict[token] = {y:1}\n",
    "            elif y not in emission_dict[token].keys():\n",
    "                emission_dict[token][y] = 1\n",
    "            else:\n",
    "                emission_dict[token][y] += 1\n",
    "            \n",
    "    # maximum likelihood estimation for emission parameters\n",
    "    for i in emission_dict.keys():\n",
    "        for k in emission_dict[i].keys():\n",
    "            emission_dict[i][k] /= y_count[k]\n",
    "    \n",
    "    return emission_dict\n",
    "\n",
    "\n",
    "# TODO: get the emission parameters for your training dataset\n",
    "\n",
    "al_emission = get_emission_parameters(al)\n",
    "cn_emission = get_emission_parameters(cn)\n",
    "en_emission = get_emission_parameters(en)\n",
    "sg_emission = get_emission_parameters(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "\n",
    "def sentiment_tag_output(emission_dict, test_file_path, output_path, token='#UNK#'):\n",
    "    \"\"\"\n",
    "    For tagging a test dataset with emission parameters from a train dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    emission_dict (dict): Dictionary of emission parameters, with format {word:{tag:count}}\n",
    "    test_file_path (string): File path of the test dataset\n",
    "    output_path (string): File path of the output sequences with predicted tags\n",
    "    token (string): Token representing unknown words in the test dataset (default #UNK#)\n",
    "    \n",
    "    \"\"\"\n",
    "    assert emission_dict != None\n",
    "    assert os.path.isfile(test_file_path)\n",
    "    assert output_path != None\n",
    "    \n",
    "    test_data = load_dataset(test_file_path)\n",
    "    \n",
    "    keys = emission_dict.keys()\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        test_data[i] = test_data[i].strip('\\n')\n",
    "        x = test_data[i]\n",
    "\n",
    "        if x != '':\n",
    "            # check if test dataset token appears in trained emission parameters, if not replace it with the unknown token\n",
    "            if x not in keys:\n",
    "                x = token\n",
    "            arg_max_y = max(emission_dict[x].items(), key=operator.itemgetter(1))[0]\n",
    "            \n",
    "            test_data[i] += ' ' + arg_max_y + '\\n'\n",
    "        else:\n",
    "            test_data[i] += '\\n'\n",
    "            continue\n",
    "    \n",
    "    # write outputs to output_path\n",
    "    with open(output_path, 'w') as f:\n",
    "        for item in test_data:\n",
    "            f.write(item)\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "# TODO: get the naive tagger output for your test dataset\n",
    "\n",
    "sentiment_tag_output(al_emission, 'dataset/al/AL/dev.in', 'dataset/al/AL/dev.p2.out')\n",
    "sentiment_tag_output(cn_emission, 'dataset/cn/CN/dev.in', 'dataset/cn/CN/dev.p2.out')\n",
    "sentiment_tag_output(en_emission, 'dataset/en/EN/dev.in', 'dataset/en/EN/dev.p2.out')\n",
    "sentiment_tag_output(sg_emission, 'dataset/sg/SG/dev.in', 'dataset/sg/SG/dev.p2.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Development Set**\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 19406\n",
      "\n",
      "#Correct Entity : 9152\n",
      "Entity  precision: 0.4716\n",
      "Entity  recall: 0.6944\n",
      "Entity  F: 0.5617\n",
      "\n",
      "#Correct Sentiment : 7644\n",
      "Sentiment  precision: 0.3939\n",
      "Sentiment  recall: 0.5800\n",
      "Sentiment  F: 0.4692\n",
      "\n",
      "\n",
      "**AL Development Set**\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 19484\n",
      "\n",
      "#Correct Entity : 2898\n",
      "Entity  precision: 0.1487\n",
      "Entity  recall: 0.3447\n",
      "Entity  F: 0.2078\n",
      "\n",
      "#Correct Sentiment : 2457\n",
      "Sentiment  precision: 0.1261\n",
      "Sentiment  recall: 0.2922\n",
      "Sentiment  F: 0.1762\n",
      "\n",
      "\n",
      "**CN Development Set**\n",
      "\n",
      "#Entity in gold data: 1478\n",
      "#Entity in prediction: 9373\n",
      "\n",
      "#Correct Entity : 765\n",
      "Entity  precision: 0.0816\n",
      "Entity  recall: 0.5176\n",
      "Entity  F: 0.1410\n",
      "\n",
      "#Correct Sentiment : 285\n",
      "Sentiment  precision: 0.0304\n",
      "Sentiment  recall: 0.1928\n",
      "Sentiment  F: 0.0525\n",
      "\n",
      "\n",
      "**SG Development Set**\n",
      "\n",
      "#Entity in gold data: 4537\n",
      "#Entity in prediction: 18451\n",
      "\n",
      "#Correct Entity : 2632\n",
      "Entity  precision: 0.1426\n",
      "Entity  recall: 0.5801\n",
      "Entity  F: 0.2290\n",
      "\n",
      "#Correct Sentiment : 1239\n",
      "Sentiment  precision: 0.0672\n",
      "Sentiment  recall: 0.2731\n",
      "Sentiment  F: 0.1078\n"
     ]
    }
   ],
   "source": [
    "# Evaluation results for Part 2\n",
    "\n",
    "print(\"\\n\\n**EN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/en/EN/dev.out dataset/en/EN/dev.p2.out\n",
    "print(\"\\n\\n**AL Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/al/AL/dev.out dataset/al/AL/dev.p2.out\n",
    "print(\"\\n\\n**CN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/cn/CN/dev.out dataset/cn/CN/dev.p2.out\n",
    "print(\"\\n\\n**SG Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/sg/SG/dev.out dataset/sg/SG/dev.p2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_parameters(train_data, start='START', stop='STOP'):\n",
    "    \"\"\"\n",
    "    For getting transition parameters for a training dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    train_data (dict): Data loaded from your training data with the \"load_dataset\" function\n",
    "    start (string): Start token representation (default START)\n",
    "    stop (string): Stop token representation (default STOP)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of transition parameters, with format {current_state:{next_state:count}}\n",
    "    \n",
    "    \"\"\"\n",
    "    assert train_data != None\n",
    "    \n",
    "    transition_dict = {}\n",
    "    y_count = {}\n",
    "    \n",
    "    # account for first missing start\n",
    "    y_count[start] = 1\n",
    "    # account for last missing stop\n",
    "    y_count[stop] = 1\n",
    "    \n",
    "    # get tag count for each tag in the training dataset\n",
    "    for d in train_data:\n",
    "        d = d.strip('\\n').split(' ')\n",
    "        try:\n",
    "            y = d[1]\n",
    "        except:\n",
    "            y_count[start] += 1\n",
    "            y_count[stop] += 1\n",
    "            continue\n",
    "        if y not in y_count.keys():\n",
    "            y_count[y] = 1\n",
    "        else:\n",
    "            y_count[y] += 1\n",
    "            \n",
    "    # process data to get transition parameters\n",
    "    for i in range(len(train_data)):\n",
    "        try:\n",
    "            y = train_data[i].strip('\\n').split(' ')[1]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            by = train_data[i-1].strip('\\n').split(' ')[1]\n",
    "        except:\n",
    "            by = start\n",
    "            \n",
    "        try:\n",
    "            fy = train_data[i+1].strip('\\n').split(' ')[1]\n",
    "        except:\n",
    "            fy = stop\n",
    "        \n",
    "        if by == start:\n",
    "            if by not in transition_dict.keys():\n",
    "                transition_dict[by] = {y:1}\n",
    "            elif y not in transition_dict[by].keys():\n",
    "                transition_dict[by][y] = 1\n",
    "            else:\n",
    "                transition_dict[by][y] += 1\n",
    "        \n",
    "        if y not in transition_dict.keys():\n",
    "            transition_dict[y] = {fy:1}\n",
    "        elif fy not in transition_dict[y].keys():\n",
    "            transition_dict[y][fy] = 1\n",
    "        else:\n",
    "            transition_dict[y][fy] += 1\n",
    "            \n",
    "    # maximum likelihood estimation for transition parameters\n",
    "    for i in transition_dict.keys():\n",
    "        for k in transition_dict[i].keys():\n",
    "            transition_dict[i][k] /= y_count[i]\n",
    "    \n",
    "    return transition_dict\n",
    "\n",
    "\n",
    "# TODO: get the transition parameters for your training dataset\n",
    "\n",
    "al_transition = get_transition_parameters(al)\n",
    "cn_transition = get_transition_parameters(cn)\n",
    "en_transition = get_transition_parameters(en)\n",
    "sg_transition = get_transition_parameters(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samson/.local/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: All-NaN axis encountered\n",
      "/home/samson/.local/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: All-NaN slice encountered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def get_viterbi_output(emission_dict, transition_dict, test_file_path, output_path, nan_layer_tag='O', best_n=1):\n",
    "    \"\"\"\n",
    "    For tagging test dataset with the Viterbi algorithm.\n",
    "    \n",
    "    emission_dict (dict): Dictionary of emission parameters, with format {word:{tag:count}}\n",
    "    transition_dict (dict): Dictionary of transition parameters, with format {current_state:{next_state:count}}\n",
    "    test_file_path (string): File path of the test dataset\n",
    "    output_path (string): File path of the output sequences with predicted tags\n",
    "    nan_layer_tag (string): Token for layers with no nodes with non-NaN values\n",
    "    best_n (int): Choice for getting best_n sequences\n",
    "    \n",
    "    \"\"\"    \n",
    "    assert transition_dict != None\n",
    "    assert best_n != None\n",
    "    assert os.path.isfile(test_file_path)\n",
    "    assert output_path != None\n",
    "    \n",
    "    test_data = load_dataset(test_file_path)\n",
    "    sequences = []\n",
    "    temp_seq = []\n",
    "    output = []\n",
    "    \n",
    "    # load test data\n",
    "    for i in range(len(test_data)):\n",
    "        test_data[i] = test_data[i].strip('\\n')\n",
    "        if test_data[i] != '':\n",
    "            temp_seq.append(test_data[i])\n",
    "        else:\n",
    "            sequences.append(temp_seq)\n",
    "            temp_seq = []\n",
    "            \n",
    "    # get set of all states\n",
    "    states = list(set([x for x in transition_dict.keys() if x != 'START'])) # correspond to columns, index 0 = first row\n",
    "    \n",
    "    for seq in sequences:\n",
    "        # recursive forward pass\n",
    "        length = len(seq) # not including START and STOP\n",
    "        scores = np.zeros((length, len(states)))\n",
    "\n",
    "        # values converted to log to prevent numerical underflow\n",
    "        for row in range(scores.shape[0]):\n",
    "            for col in range(scores.shape[1]):\n",
    "                if row == 0:\n",
    "                    try:\n",
    "                        if seq[row] in emission_dict.keys():\n",
    "                            scores[row,col] = 1 + np.log(transition_dict['START'][states[col]]) + np.log(emission_dict[seq[row]][states[col]])\n",
    "                        else:\n",
    "                            scores[row,col] = 1 + np.log(transition_dict['START'][states[col]]) + np.log(emission_dict['#UNK#'][states[col]])\n",
    "                    except:\n",
    "                        scores[row,col] = np.nan\n",
    "                else:\n",
    "                    state_score = []\n",
    "                    for prev_state in range(len(states)):\n",
    "                        try:\n",
    "                            if seq[row] in emission_dict.keys():\n",
    "                                score = scores[row-1,prev_state] + np.log(transition_dict[states[prev_state]][states[col]]) + np.log(emission_dict[seq[row]][states[col]])\n",
    "                            else:\n",
    "                                score = scores[row-1,prev_state] + np.log(transition_dict[states[prev_state]][states[col]]) + np.log(emission_dict['#UNK#'][states[col]])\n",
    "                        except:\n",
    "                            score = np.nan\n",
    "                        state_score.append(score)\n",
    "                    scores[row,col] = np.nanmax(state_score)\n",
    "                            \n",
    "            min_score = np.nanmin(scores[row,:])\n",
    "            \n",
    "            # post-process to make sure no zeros and no negatives for next row's log operations by adding the absolute value of the smallest node value with a small constant\n",
    "            for col in range(len(states)):\n",
    "                if np.isnan(scores[row,col]):\n",
    "                    pass\n",
    "                else:\n",
    "                    scores[row,col] += np.abs(min_score) + 1e-5\n",
    "        \n",
    "        # search for the best_n path's last node\n",
    "        tags = []\n",
    "        left = best_n\n",
    "        ignored_layers = 0\n",
    "        \n",
    "        for row in range(length-1,-1,-1):\n",
    "            STOP = np.zeros(len(states))\n",
    "\n",
    "            for col in range(len(states)):\n",
    "                try:\n",
    "                    STOP[col] = scores[row,col] + np.log(transition_dict[states[col]]['STOP'])\n",
    "                except:\n",
    "                    STOP[col] = np.nan\n",
    "                    \n",
    "            # check the number of non-nan values in the layer\n",
    "            num_valid_values = STOP.size - np.isnan(STOP).sum()\n",
    "            \n",
    "            if left - num_valid_values <= 0:\n",
    "                # get best_n node\n",
    "                index_choice = np.argsort(STOP)[-left-np.isnan(STOP).sum()]\n",
    "                tags.append(states[index_choice])\n",
    "                ignored_layers += 1\n",
    "                break\n",
    "            else:\n",
    "                # if last layer(s) do not have sufficient nodes with non-NaN scores for the best_n sequence, we continue looking\n",
    "                left -= num_valid_values\n",
    "                ignored_layers += 1\n",
    "                tags.append(nan_layer_tag)\n",
    "        \n",
    "        # backward pass for best_n path\n",
    "        if ignored_layers > 1:\n",
    "            # get the best tags for the case where the last valid layer is not the last layer before STOP\n",
    "            backward_score = np.asarray([])\n",
    "            \n",
    "            # get the best tag for the last valid layer if it is not the last layer before STOP\n",
    "            for col in range(len(states)):\n",
    "                # only use the emission parameters for last valid layer if it is not the last layer before STOP\n",
    "                # experimentally, this provides better accuracy than considering the transition parameters to a fake STOP\n",
    "                try:\n",
    "                    backward_score = np.append(backward_score, scores[length-1-ignored_layers,col])\n",
    "                except:\n",
    "                    backward_score = np.append(backward_score, np.nan)      \n",
    "            try:\n",
    "                index_choice = np.argsort(backward_score)[-1-np.isnan(backward_score).sum()]\n",
    "                tags.append(states[index_choice])\n",
    "            except:\n",
    "                tags.append(nan_layer_tag)\n",
    "                                  \n",
    "            # get the best tag for the previous layers\n",
    "            for row in range(length-2-ignored_layers,-1,-1):\n",
    "                backward_score = np.asarray([])\n",
    "                for col in range(len(states)):\n",
    "                    try:\n",
    "                        backward_score = np.append(backward_score, scores[row,col] * transition_dict[states[col]][tags[-1]])\n",
    "                    except:\n",
    "                        backward_score = np.append(backward_score, np.nan)      \n",
    "                try:\n",
    "                    index_choice = np.argsort(backward_score)[-1-np.isnan(backward_score).sum()]\n",
    "                    tags.append(states[index_choice])\n",
    "                except:\n",
    "                    tags.append(nan_layer_tag)\n",
    "        else:\n",
    "            # get the best tags for the case where the last valid layer is the last layer before STOP\n",
    "            for row in range(length-2,-1,-1):\n",
    "                backward_score = np.asarray([])\n",
    "                for col in range(len(states)):\n",
    "                    try:\n",
    "                        backward_score = np.append(backward_score, scores[row,col] * transition_dict[states[col]][tags[-1]])\n",
    "                    except:\n",
    "                        backward_score = np.append(backward_score, np.nan)      \n",
    "                try:\n",
    "                    index_choice = np.argsort(backward_score)[-1-np.isnan(backward_score).sum()]\n",
    "                    tags.append(states[index_choice])\n",
    "                except:\n",
    "                    tags.append(nan_layer_tag)\n",
    "            \n",
    "        # reverse tag outputs\n",
    "        tags.reverse()\n",
    "        \n",
    "        for i in range(len(seq)):\n",
    "            output.append(seq[i] + ' ' + tags[i] + '\\n')\n",
    "        output.append('\\n')\n",
    "        \n",
    "    # write outputs to output_path\n",
    "    with open(output_path, 'w') as f:\n",
    "        for item in output:\n",
    "            f.write(item)\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "# TODO: get the Viterbi algorithm's best outputs for your test dataset\n",
    "        \n",
    "get_viterbi_output(al_emission, al_transition, 'dataset/al/AL/dev.in', 'dataset/al/AL/dev.p3.out', nan_layer_tag='B-REDUNDANT')\n",
    "get_viterbi_output(cn_emission, cn_transition, 'dataset/cn/CN/dev.in', 'dataset/cn/CN/dev.p3.out')\n",
    "get_viterbi_output(en_emission, en_transition, 'dataset/en/EN/dev.in', 'dataset/en/EN/dev.p3.out')\n",
    "get_viterbi_output(sg_emission, sg_transition, 'dataset/sg/SG/dev.in', 'dataset/sg/SG/dev.p3.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Development Set**\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 14106\n",
      "\n",
      "#Correct Entity : 9584\n",
      "Entity  precision: 0.6794\n",
      "Entity  recall: 0.7272\n",
      "Entity  F: 0.7025\n",
      "\n",
      "#Correct Sentiment : 8700\n",
      "Sentiment  precision: 0.6168\n",
      "Sentiment  recall: 0.6601\n",
      "Sentiment  F: 0.6377\n",
      "\n",
      "\n",
      "**AL Development Set**\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 10372\n",
      "\n",
      "#Correct Entity : 4940\n",
      "Entity  precision: 0.4763\n",
      "Entity  recall: 0.5875\n",
      "Entity  F: 0.5261\n",
      "\n",
      "#Correct Sentiment : 3320\n",
      "Sentiment  precision: 0.3201\n",
      "Sentiment  recall: 0.3949\n",
      "Sentiment  F: 0.3536\n",
      "\n",
      "\n",
      "**CN Development Set**\n",
      "\n",
      "#Entity in gold data: 1478\n",
      "#Entity in prediction: 707\n",
      "\n",
      "#Correct Entity : 294\n",
      "Entity  precision: 0.4158\n",
      "Entity  recall: 0.1989\n",
      "Entity  F: 0.2691\n",
      "\n",
      "#Correct Sentiment : 200\n",
      "Sentiment  precision: 0.2829\n",
      "Sentiment  recall: 0.1353\n",
      "Sentiment  F: 0.1831\n",
      "\n",
      "\n",
      "**SG Development Set**\n",
      "\n",
      "#Entity in gold data: 4537\n",
      "#Entity in prediction: 2682\n",
      "\n",
      "#Correct Entity : 1586\n",
      "Entity  precision: 0.5913\n",
      "Entity  recall: 0.3496\n",
      "Entity  F: 0.4394\n",
      "\n",
      "#Correct Sentiment : 969\n",
      "Sentiment  precision: 0.3613\n",
      "Sentiment  recall: 0.2136\n",
      "Sentiment  F: 0.2685\n"
     ]
    }
   ],
   "source": [
    "# Evaluation results for Part 3\n",
    "\n",
    "print(\"\\n\\n**EN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/en/EN/dev.out dataset/en/EN/dev.p3.out\n",
    "print(\"\\n\\n**AL Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/al/AL/dev.out dataset/al/AL/dev.p3.out\n",
    "print(\"\\n\\n**CN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/cn/CN/dev.out dataset/cn/CN/dev.p3.out\n",
    "print(\"\\n\\n**SG Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/sg/SG/dev.out dataset/sg/SG/dev.p3.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samson/.local/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: All-NaN axis encountered\n",
      "/home/samson/.local/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Development Set**\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 13711\n",
      "\n",
      "#Correct Entity : 8826\n",
      "Entity  precision: 0.6437\n",
      "Entity  recall: 0.6697\n",
      "Entity  F: 0.6565\n",
      "\n",
      "#Correct Sentiment : 7959\n",
      "Sentiment  precision: 0.5805\n",
      "Sentiment  recall: 0.6039\n",
      "Sentiment  F: 0.5920\n",
      "\n",
      "\n",
      "**AL Development Set**\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 11380\n",
      "\n",
      "#Correct Entity : 4108\n",
      "Entity  precision: 0.3610\n",
      "Entity  recall: 0.4886\n",
      "Entity  F: 0.4152\n",
      "\n",
      "#Correct Sentiment : 2113\n",
      "Sentiment  precision: 0.1857\n",
      "Sentiment  recall: 0.2513\n",
      "Sentiment  F: 0.2136\n"
     ]
    }
   ],
   "source": [
    "# TODO: get the Viterbi algorithm's 7th best outputs for your test dataset\n",
    "\n",
    "get_viterbi_output(al_emission, al_transition, 'dataset/al/AL/dev.in', 'dataset/al/AL/dev.p4.out', best_n=7, nan_layer_tag='B-REDUNDANT')\n",
    "get_viterbi_output(en_emission, en_transition, 'dataset/en/EN/dev.in', 'dataset/en/EN/dev.p4.out', best_n=7)\n",
    "\n",
    "# Evaluation results for Part 4\n",
    "\n",
    "print(\"\\n\\n**EN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/en/EN/dev.out dataset/en/EN/dev.p4.out\n",
    "print(\"\\n\\n**AL Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/al/AL/dev.out dataset/al/AL/dev.p4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 – Design Challenge (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Development Set**\n",
      "Training done for epoch 1...\n",
      "Training done for epoch 2...\n",
      "Training done for epoch 3...\n",
      "Training done for epoch 4...\n",
      "Training done for epoch 5...\n",
      "\n",
      "\n",
      "Prediction done for 100 test sequences...\n",
      "Prediction done for 200 test sequences...\n",
      "Prediction done for 300 test sequences...\n",
      "Prediction done for 400 test sequences...\n",
      "Prediction done for 500 test sequences...\n",
      "Prediction done for 600 test sequences...\n",
      "Prediction done for 700 test sequences...\n",
      "Prediction done for 800 test sequences...\n",
      "Prediction done for 900 test sequences...\n",
      "Prediction done for 1000 test sequences...\n",
      "\n",
      "Test results written to ./dataset/en/EN/dev.p5.out!\n",
      "\n",
      "\n",
      "**AL Development Set**\n",
      "Training done for epoch 1...\n",
      "Training done for epoch 2...\n",
      "Training done for epoch 3...\n",
      "Training done for epoch 4...\n",
      "Training done for epoch 5...\n",
      "Training done for epoch 6...\n",
      "Training done for epoch 7...\n",
      "Training done for epoch 8...\n",
      "Training done for epoch 9...\n",
      "Training done for epoch 10...\n",
      "\n",
      "\n",
      "Prediction done for 100 test sequences...\n",
      "Prediction done for 200 test sequences...\n",
      "Prediction done for 300 test sequences...\n",
      "Prediction done for 400 test sequences...\n",
      "Prediction done for 500 test sequences...\n",
      "Prediction done for 600 test sequences...\n",
      "Prediction done for 700 test sequences...\n",
      "Prediction done for 800 test sequences...\n",
      "Prediction done for 900 test sequences...\n",
      "Prediction done for 1000 test sequences...\n",
      "Prediction done for 1100 test sequences...\n",
      "Prediction done for 1200 test sequences...\n",
      "Prediction done for 1300 test sequences...\n",
      "Prediction done for 1400 test sequences...\n",
      "\n",
      "Test results written to ./dataset/al/AL/dev.p5.out!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "    \n",
    "class AveragedPerceptronTagger:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialisation of necessary components for the averaged perceptron tagger.\n",
    "        \"\"\"\n",
    "        # records each timestep and timestep each feature is last updated\n",
    "        self.time = 0\n",
    "        self.update_time = defaultdict(lambda: defaultdict(int))\n",
    "        # stores the tag that are most likely to be emitted by each word, depending on the frequency and ambiguity thresholds\n",
    "        self.tagdict = {}\n",
    "        # set of all tags\n",
    "        self.tags = set()\n",
    "        # stores weights, in {feature:{tag:weight} format\n",
    "        self.weights = {}\n",
    "        # cumulative total of the weights\n",
    "        self.total_weights = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        \n",
    "    def get_features(self, i, word, sequence, past_tags, language):\n",
    "        \"\"\"\n",
    "        Feature templates for creating features.\n",
    "        \n",
    "        Parameters:\n",
    "        i (int): Timestep of the sentence being considered\n",
    "        word (string): Word in the sentence being considered\n",
    "        sequence (list): The sequence being considered\n",
    "        past_tags (list): List of the tags already predicted\n",
    "        language (string): Language to determine choice of feature templates\n",
    "        \n",
    "        Returns:\n",
    "        dict: Dictionary of the feature representation of a word/token in a sequence\n",
    "        \n",
    "        \"\"\"\n",
    "        def add_feature(name, *args):\n",
    "            \"\"\"\n",
    "            Add feature to feature dictionary.\n",
    "            \n",
    "            Parameters:\n",
    "            *args (string): String representations of values to be added to feature representation\n",
    "            \n",
    "            \"\"\"\n",
    "            features[' '.join((name,) + tuple(args))] += 1\n",
    "\n",
    "        features = defaultdict(int)\n",
    "        \n",
    "        if language == \"english\":\n",
    "            add_feature('bias')\n",
    "            add_feature('word_length', str(len(word)))\n",
    "            add_feature('is_capitalized', str(word[0].upper() == word[0]))\n",
    "            add_feature('is_all_capitalized', str(word.upper() == word))\n",
    "            add_feature('is_capitals_inside', str(word[1:].lower() != word[1:]))\n",
    "            add_feature('is_numeric', str(word.isdigit()))\n",
    "            add_feature('contains_num', str(any(char.isdigit() for char in word)))\n",
    "            add_feature('3-prev-tag', '' if i < 3 else past_tags[i-3])\n",
    "            add_feature('2-prev-tag', '' if i < 2 else past_tags[i-2])\n",
    "            add_feature('prev-tag', '' if i < 1 else past_tags[i-1])\n",
    "            add_feature('suffix-1', word[-1:])\n",
    "            add_feature('suffix-2', '' if len(word) < 2 else word[-2:])\n",
    "            add_feature('suffix-3', '' if len(word) < 3 else word[-3:])\n",
    "            add_feature('prefix-1', word[0])\n",
    "            add_feature('prefix-2', '' if len(word) < 2 else word[:2])\n",
    "            add_feature('prefix-3', '' if len(word) < 3 else word[:3])\n",
    "            add_feature('word', word)\n",
    "            add_feature('prev-word', '' if i < 1 else sequence[i-1])\n",
    "            add_feature('prev-word-with-tag', '' if i < 1 else sequence[i-1] + ' ' + past_tags[i-1])\n",
    "            add_feature('2-prev-word-with-tag', '' if i < 2 else sequence[i-2] + ' ' + past_tags[i-2])\n",
    "            add_feature('3-prev-word-with-tag', '' if i < 3 else sequence[i-3] + ' ' + past_tags[i-3])\n",
    "            add_feature('2-prev-word', '' if i < 2 else sequence[i-2])\n",
    "            add_feature('3-prev-word', '' if i < 3 else sequence[i-3])\n",
    "            add_feature('next-word', '' if i >= len(sequence)-1 else sequence[i+1])\n",
    "            add_feature('2-next-word', '' if i >= len(sequence)-2 else sequence[i+2])\n",
    "            add_feature('3-next-word', '' if i >= len(sequence)-3 else sequence[i+3])\n",
    "        elif language == \"chinese\":\n",
    "            add_feature('bias')\n",
    "            add_feature('is_first', str(i==0))\n",
    "            add_feature('is_last', str(i==len(sequence)-1))\n",
    "            add_feature('is_numeric', str(word.isdigit()))\n",
    "            add_feature('is_alphanumeric', str(word.isalnum()))\n",
    "            add_feature('4-prev-tag', '' if i < 4 else past_tags[i-4])\n",
    "            add_feature('3-prev-tag', '' if i < 3 else past_tags[i-3])\n",
    "            add_feature('2-prev-tag', '' if i < 2 else past_tags[i-2])\n",
    "            add_feature('prev-tag', '' if i < 1 else past_tags[i-1])\n",
    "            add_feature('word', word)\n",
    "            add_feature('prev-word', '' if i < 1 else sequence[i-1])\n",
    "            add_feature('prev-word-with-tag', '' if i < 1 else sequence[i-1] + ' ' + past_tags[i-1])\n",
    "            add_feature('2-prev-word-with-tag', '' if i < 2 else sequence[i-2] + ' ' + past_tags[i-2])\n",
    "            add_feature('3-prev-word-with-tag', '' if i < 3 else sequence[i-3] + ' ' + past_tags[i-3])\n",
    "            add_feature('2-prev-word', '' if i < 2 else sequence[i-2])\n",
    "            add_feature('3-prev-word', '' if i < 3 else sequence[i-3])\n",
    "            add_feature('next-word', '' if i >= len(sequence)-1 else sequence[i+1])\n",
    "            add_feature('2-next-word', '' if i >= len(sequence)-2 else sequence[i+2])\n",
    "            add_feature('3-next-word', '' if i >= len(sequence)-3 else sequence[i+3])\n",
    "            add_feature('prev-curr-next-word', '' if i < 1 else sequence[i-1], sequence[i], '' if i >= len(sequence)-1 else sequence[i+1])\n",
    "            add_feature('prev-curr-word', '' if i < 1 else sequence[i-1], sequence[i])\n",
    "            add_feature('curr-next-word', sequence[i], '' if i >= len(sequence)-1 else sequence[i+1])\n",
    "            add_feature('2-prev-curr-2-next-word', '' if i < 2 else sequence[i-2], '' if i < 1 else sequence[i-1], sequence[i], '' if i >= len(sequence)-1 else sequence[i+1], '' if i >= len(sequence)-2 else sequence[i+2])\n",
    "        else:\n",
    "            raise Exception('Please make sure you choose either \"english\" or \"chinese\" for the language during training and/or tagging.')\n",
    "        \n",
    "        return features\n",
    "        \n",
    "        \n",
    "    def train(self, train_text_path, language, freq_thresh=5,  ambiguity_thresh=0.98, it=1, lr=1.0):\n",
    "        \"\"\"\n",
    "        Train averaged perceptron model.\n",
    "        \n",
    "        Parameters:\n",
    "        train_text_path (string): File path of the training dataset\n",
    "        language (string): Language to determine choice of feature templates\n",
    "        freq_thresh (int): Frequency threshold to determine whether a word should be stored for easier non-predictive tagging (default 5)\n",
    "        ambiguity_thresh (float): Ambiguity threshold to determine whether a word should be stored for easier non-predictive tagging (default 0.95)\n",
    "        it (int): Number of epochs to train the averaged perceptron model for (default 1)\n",
    "        lr (float): A value between 0.0 and 1.0 to determine how much to update the weights for each classification mistake (default 1.0)\n",
    "        \n",
    "        \"\"\"\n",
    "        assert train_text_path is not None\n",
    "        assert type(freq_thresh) == int\n",
    "        assert type(ambiguity_thresh) == float\n",
    "        assert language is not None\n",
    "        assert type(lr) == float\n",
    "        assert lr >= 0\n",
    "        assert lr <= 1\n",
    "\n",
    "        # load training data\n",
    "        with open(train_text_path) as file:\n",
    "            train_data = file.readlines()\n",
    "        file.close()\n",
    "      \n",
    "        words = []\n",
    "        tags = []\n",
    "        sequences = []\n",
    "\n",
    "        # check for uncommon words\n",
    "        freq = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        # get training sequences\n",
    "        for i in range(len(train_data)):\n",
    "            train_data[i] = train_data[i].strip('\\n')\n",
    "            if train_data[i] != '':\n",
    "                data = train_data[i].split(' ')\n",
    "                words.append(data[0])\n",
    "                tags.append(data[1])\n",
    "                freq[data[0]][data[1]] += 1\n",
    "                if data[1] not in self.tags:\n",
    "                    self.tags.add(data[1])\n",
    "            else:\n",
    "                sequences.append((words,tags))\n",
    "                words = []\n",
    "                tags = []\n",
    "\n",
    "        # check for common and unambiguous words that can be added to tag dictionary for easier, non-predictive access\n",
    "        for word, tag in freq.items():\n",
    "            # get most common tag count\n",
    "            most_common_tag, most_common_tag_count = max(tag.items(), key=lambda item: item[1])\n",
    "            # get word count\n",
    "            word_count = sum(tag.values())\n",
    "            # make sure tag appears often enough and belongs to a certain tag at a rate more than ambiguity_thresh\n",
    "            if float(most_common_tag_count) / word_count >= ambiguity_thresh and word_count >= freq_thresh:\n",
    "                self.tagdict[word] = most_common_tag\n",
    "\n",
    "        # training the model\n",
    "        for i in range(it):\n",
    "            for seq, tags in sequences:\n",
    "                past_tags=[]\n",
    "                for j, word in enumerate(seq):\n",
    "                    # get tag prediction if it is the usual one for the word, from the easy access tag dictionary\n",
    "                    y_pred = self.tagdict.get(word)\n",
    "                    \n",
    "                    # use perceptron prediction if it is not\n",
    "                    if not y_pred:\n",
    "                        # update time for each perceptron run\n",
    "                        self.time += 1\n",
    "                        \n",
    "                        feats = self.get_features(j, word, seq, past_tags, language)\n",
    "                        y_pred = self.predict(feats)\n",
    "\n",
    "                        # if prediction is incorrect --> update weight for each feature according to perceptron rules\n",
    "                        if y_pred != tags[j]:\n",
    "                            for feat in feats:\n",
    "                                feature_weight = self.weights.setdefault(feat, {})\n",
    "                                \n",
    "                                # update weight for ground truth tag\n",
    "                                real_tag_weight = feature_weight.get(tags[j], 0.0)\n",
    "                                self.total_weights[feat][tags[j]] += (self.time - self.update_time[feat][tags[j]]) * real_tag_weight\n",
    "                                self.update_time[feat][tags[j]] = self.time\n",
    "                                self.weights[feat][tags[j]] = real_tag_weight + lr * 1.0\n",
    "                                \n",
    "                                # update weight for y_pred tag\n",
    "                                pred_tag_weight = feature_weight.get(y_pred, 0.0)\n",
    "                                self.total_weights[feat][y_pred] += (self.time - self.update_time[feat][y_pred]) * pred_tag_weight\n",
    "                                self.update_time[feat][y_pred] = self.time\n",
    "                                self.weights[feat][y_pred] = pred_tag_weight + lr * (-1.0)\n",
    "                    \n",
    "                    past_tags.append(y_pred)\n",
    "                    \n",
    "            # shuffle sequences after each epoch for more balanced updates        \n",
    "            random.shuffle(sequences)\n",
    "\n",
    "            print(\"Training done for epoch \" + str(i + 1) + \"...\")\n",
    "        \n",
    "        # average weights for each feature across all timesteps\n",
    "        for feature, feat_tag_weights in self.weights.items():\n",
    "            averaged_feat_weights = {}\n",
    "            for tag, tag_weight in feat_tag_weights.items():\n",
    "                # update total weights for all features and all tags\n",
    "                self.total_weights[feature][tag] += (self.time - self.update_time[feature][tag]) * tag_weight\n",
    "                averaged =  self.total_weights[feature][tag] / float(self.time)\n",
    "                if averaged is not None:\n",
    "                    averaged_feat_weights[tag] = averaged\n",
    "            self.weights[feature] = averaged_feat_weights\n",
    "        \n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Predict best tag based on features and current weights.\n",
    "        \n",
    "        Parameters:\n",
    "        features (dict): Dictionary with feature names and feature values\n",
    "        \n",
    "        Returns:\n",
    "        string: Most likely tag output for the feature representation passed in\n",
    "        \n",
    "        \"\"\"\n",
    "        scores = defaultdict(float)\n",
    "        # get features\n",
    "        for feat, feat_value in features.items():\n",
    "            if feat in self.weights:\n",
    "                # get feature and tag pair weight\n",
    "                feat_tag_weights = self.weights[feat]\n",
    "                for tag, tag_weight in feat_tag_weights.items():\n",
    "                    scores[tag] += feat_value * tag_weight\n",
    "\n",
    "        # return tag with the best score, after going through all features\n",
    "        return max(self.tags, key=lambda tag: (scores[tag], tag))\n",
    "\n",
    "        \n",
    "    def tag(self, test_text_path, output_path, language, show_freq=100):\n",
    "        \"\"\"\n",
    "        Tag test sequences.\n",
    "        \n",
    "        Parameters:\n",
    "        test_text_path (string): File path of the test dataset\n",
    "        output_path (string): File path of the output sequences with predicted tags\n",
    "        language (string): Language to determine choice of feature templates\n",
    "        show_freq (int): How many predictions to complete before printing progress to the console (default 100)\n",
    "        \n",
    "        \"\"\"\n",
    "        assert test_text_path is not None\n",
    "        assert output_path is not None\n",
    "        assert language is not None\n",
    "        assert type(show_freq) == int\n",
    "\n",
    "        # load test data\n",
    "        with open(test_text_path) as file:\n",
    "            test_data = file.readlines()\n",
    "        file.close()\n",
    "\n",
    "        # get test sequences\n",
    "        test_seq = []\n",
    "        temp_input = []\n",
    "        for i in range(len(test_data)):\n",
    "            test_data[i] = test_data[i].strip('\\n')\n",
    "            if test_data[i] != '':\n",
    "                temp_input.append(test_data[i])\n",
    "            else:\n",
    "                test_seq.append(temp_input)\n",
    "                temp_input = []\n",
    "\n",
    "        output = []\n",
    "        count = 0\n",
    "\n",
    "        print(\"\\n\")\n",
    "        for seq in test_seq:\n",
    "            past_tags = []\n",
    "            count += 1\n",
    "\n",
    "            for i, word in enumerate(seq):\n",
    "                # check if word exists in the easy access tag dictionary\n",
    "                y_pred = self.tagdict.get(word)\n",
    "                if not y_pred:\n",
    "                    feats = self.get_features(i, word, seq, past_tags, language)\n",
    "                    y_pred = self.predict(feats)\n",
    "                past_tags.append(y_pred)\n",
    "                output.append(word + ' ' + y_pred + '\\n')\n",
    "            \n",
    "            output.append('\\n')\n",
    "\n",
    "            if count % show_freq == 0:\n",
    "                print(\"Prediction done for \" + str(count) + \" test sequences...\")\n",
    "        \n",
    "        # write model predictions as outputs to output_path\n",
    "        with open(output_path, 'w') as f:\n",
    "            for item in output:\n",
    "                f.write(item)\n",
    "        f.close()\n",
    "\n",
    "        print('\\nOutputs written to ' + str(output_path) + '!')\n",
    "\n",
    "        \n",
    "# TODO: get the averaged perceptron outputs for your test dataset\n",
    "        \n",
    "print(\"\\n\\n**EN Development Set**\")\n",
    "en_tagger = AveragedPerceptronTagger()\n",
    "en_tagger.train('./dataset/en/EN/train', it=5, language='english')\n",
    "en_tagger.tag('./dataset/en/EN/dev.in','./dataset/en/EN/dev.p5.out', language='english')\n",
    "\n",
    "print(\"\\n\\n**AL Development Set**\")\n",
    "al_tagger = AveragedPerceptronTagger()\n",
    "al_tagger.train('./dataset/al/AL/train', it=10, language='chinese')\n",
    "al_tagger.tag('./dataset/al/AL/dev.in','./dataset/al/AL/dev.p5.out', language='chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Development Set**\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 13427\n",
      "\n",
      "#Correct Entity : 12141\n",
      "Entity  precision: 0.9042\n",
      "Entity  recall: 0.9212\n",
      "Entity  F: 0.9127\n",
      "\n",
      "#Correct Sentiment : 11872\n",
      "Sentiment  precision: 0.8842\n",
      "Sentiment  recall: 0.9008\n",
      "Sentiment  F: 0.8924\n",
      "\n",
      "\n",
      "**AL Development Set**\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 8776\n",
      "\n",
      "#Correct Entity : 7597\n",
      "Entity  precision: 0.8657\n",
      "Entity  recall: 0.9035\n",
      "Entity  F: 0.8842\n",
      "\n",
      "#Correct Sentiment : 7168\n",
      "Sentiment  precision: 0.8168\n",
      "Sentiment  recall: 0.8525\n",
      "Sentiment  F: 0.8343\n"
     ]
    }
   ],
   "source": [
    "# Evaluation results for Part 5\n",
    "\n",
    "print(\"\\n\\n**EN Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/en/EN/dev.out dataset/en/EN/dev.p5.out\n",
    "print(\"\\n\\n**AL Development Set**\")\n",
    "!python3 evalscript/evalResult.py dataset/al/AL/dev.out dataset/al/AL/dev.p5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**EN Test Set**\n",
      "\n",
      "\n",
      "Prediction done for 100 test sequences...\n",
      "Prediction done for 200 test sequences...\n",
      "Prediction done for 300 test sequences...\n",
      "Prediction done for 400 test sequences...\n",
      "Prediction done for 500 test sequences...\n",
      "Prediction done for 600 test sequences...\n",
      "Prediction done for 700 test sequences...\n",
      "Prediction done for 800 test sequences...\n",
      "Prediction done for 900 test sequences...\n",
      "Prediction done for 1000 test sequences...\n",
      "Prediction done for 1100 test sequences...\n",
      "Prediction done for 1200 test sequences...\n",
      "Prediction done for 1300 test sequences...\n",
      "Prediction done for 1400 test sequences...\n",
      "Prediction done for 1500 test sequences...\n",
      "Prediction done for 1600 test sequences...\n",
      "Prediction done for 1700 test sequences...\n",
      "Prediction done for 1800 test sequences...\n",
      "Prediction done for 1900 test sequences...\n",
      "Prediction done for 2000 test sequences...\n",
      "Prediction done for 2100 test sequences...\n",
      "\n",
      "Test results written to ./dataset/en/EN/test.p5.out!\n",
      "\n",
      "\n",
      "**AL Test Set**\n",
      "\n",
      "\n",
      "Prediction done for 100 test sequences...\n",
      "Prediction done for 200 test sequences...\n",
      "Prediction done for 300 test sequences...\n",
      "Prediction done for 400 test sequences...\n",
      "Prediction done for 500 test sequences...\n",
      "Prediction done for 600 test sequences...\n",
      "Prediction done for 700 test sequences...\n",
      "Prediction done for 800 test sequences...\n",
      "Prediction done for 900 test sequences...\n",
      "Prediction done for 1000 test sequences...\n",
      "Prediction done for 1100 test sequences...\n",
      "Prediction done for 1200 test sequences...\n",
      "Prediction done for 1300 test sequences...\n",
      "Prediction done for 1400 test sequences...\n",
      "Prediction done for 1500 test sequences...\n",
      "Prediction done for 1600 test sequences...\n",
      "Prediction done for 1700 test sequences...\n",
      "Prediction done for 1800 test sequences...\n",
      "Prediction done for 1900 test sequences...\n",
      "Prediction done for 2000 test sequences...\n",
      "Prediction done for 2100 test sequences...\n",
      "Prediction done for 2200 test sequences...\n",
      "Prediction done for 2300 test sequences...\n",
      "Prediction done for 2400 test sequences...\n",
      "Prediction done for 2500 test sequences...\n",
      "Prediction done for 2600 test sequences...\n",
      "Prediction done for 2700 test sequences...\n",
      "Prediction done for 2800 test sequences...\n",
      "Prediction done for 2900 test sequences...\n",
      "\n",
      "Test results written to ./dataset/al/AL/test.p5.out!\n"
     ]
    }
   ],
   "source": [
    "# Test set predictions for Part 5\n",
    "\n",
    "print(\"\\n\\n**EN Test Set**\")\n",
    "en_tagger.tag('./dataset/en/EN/test.in','./dataset/en/EN/test.p5.out', language='english')\n",
    "print(\"\\n\\n**AL Test Set**\")\n",
    "al_tagger.tag('./dataset/al/AL/test.in','./dataset/al/AL/test.p5.out', language='chinese')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
